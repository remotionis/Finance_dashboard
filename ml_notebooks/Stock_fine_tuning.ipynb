{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhFA-F8QNv3J",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "AWS_ACCESS_KEY_ID = None\n",
    "AWS_SECRET_ACCESS_KEY = None\n",
    "target_date = None"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import botocore.exceptions\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ],
   "metadata": {
    "id": "gyXmzcE6BKYQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "aws_access_key_id = AWS_ACCESS_KEY_ID\n",
    "aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket_name = \"de6-team7-bucket\"\n",
    "prefix = f\"derived_stock/stock_dt={target_date}/\""
   ],
   "metadata": {
    "id": "_RiNw_onBNLO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 포맷 확인 후 가능한 경우 포맷 맞춰 변환, 불가능하면 None 반환\n",
    "def try_convert(s, fmt=\"%Y-%m-%d %H:%M:%S\"):\n",
    "    try:\n",
    "        dt = pd.to_datetime(s, errors='raise')  # 실패하면 예외 발생\n",
    "        return dt.strftime(fmt)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def load_data(exec_date_str: str) -> pd.DataFrame:\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    if 'Contents' not in response:\n",
    "        print(f\"누락된 날짜: {target_date} - 데이터 없음\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    file_keys = [obj['Key'] for obj in response.get('Contents', []) if obj['Key'].endswith('.parquet')]\n",
    "    if not file_keys:\n",
    "        print(f\"Parquet 파일 없음: {target_date}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_list = []\n",
    "    for key in file_keys:\n",
    "        s3_object = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "        buffer = io.BytesIO(s3_object['Body'].read())\n",
    "        df_temp = pd.read_parquet(buffer)\n",
    "        #print(df_temp.head())\n",
    "\n",
    "        df_temp = df_temp[['trade_time_min', 'stock_code', 'open_price', 'high_price', 'low_price', 'close_price', 'cum_volume', 'cum_amount', 'vwap_price', 'change_rate', 'spread']]\n",
    "\n",
    "        df_temp['trade_time_min'] = target_date + \" \" + df_temp['trade_time_min'].astype(str)\n",
    "        df_temp['trade_time_min'] = df_temp.apply(lambda row: try_convert(row['trade_time_min']), axis=1)\n",
    "        df_list.append(df_temp)\n",
    "\n",
    "    print(f\"{target_date} → {len(file_keys)}개 파일 불러옴\")\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ],
   "metadata": {
    "id": "Rvb6uatpBTWh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_features(df, price_change_threshold=0.002):\n",
    "    try:\n",
    "        # --- 추가 전처리 ---\n",
    "        df.sort_values(by=['trade_time_min', 'stock_code'], inplace=True)\n",
    "        df['stock_code'] = df['stock_code'].astype('category')\n",
    "        df['future_avg_price'] = (\n",
    "            df.groupby('stock_code')['close_price'].transform(lambda x: x.rolling(window=1, min_periods=1).mean().shift(-1))\n",
    "        )\n",
    "        df['future_return'] = (df['future_avg_price'] - df['close_price']) / df['close_price']\n",
    "        df['target_direction'] = np.select(\n",
    "            [df['future_return'] > price_change_threshold,\n",
    "            df['future_return'] < -price_change_threshold],\n",
    "            [2, 0], default=1\n",
    "        )\n",
    "        print('전:', df.shape)\n",
    "        df.dropna(subset=['future_avg_price', 'future_return'], inplace=True)\n",
    "        print('후:', df.shape)\n",
    "        if df.empty:\n",
    "            print(\"Empty dataframe\")\n",
    "            return pd.DataFrame()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return pd.DataFrame()"
   ],
   "metadata": {
    "id": "lco-tSNxCntA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def check_booster_exists(bucket_name: str, s3_key: str) -> bool:\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "        return True  # 파일이 존재함\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False  # 파일이 존재하지 않음\n",
    "        else:\n",
    "            raise  # 다른 예외는 그대로 raise"
   ],
   "metadata": {
    "id": "UlPLhjj9CvUh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_booster(model_type='clf'):\n",
    "    try:\n",
    "        model_path = \"/tmp/\"\n",
    "        if model_type == 'reg':\n",
    "            booster_name = \"stock_reg_booster.txt\"\n",
    "            params_name = \"stock_reg_params.json\"\n",
    "        else:\n",
    "            booster_name = \"stock_clf_booster.txt\"\n",
    "            params_name = \"stock_clf_params.json\"\n",
    "\n",
    "        s3_booster_key = f'models/stock/{booster_name}'\n",
    "        s3_params_key = f'models/stock/{params_name}'\n",
    "\n",
    "        if check_booster_exists(bucket_name, s3_booster_key):\n",
    "            s3_client.download_file(bucket_name, s3_booster_key, model_path+booster_name)  # booster download\n",
    "            s3_client.download_file(bucket_name, s3_params_key, model_path+params_name)  # params download\n",
    "            booster = lgb.Booster(model_file=model_path+booster_name)\n",
    "            with open(model_path+params_name, 'r') as f:\n",
    "                params = json.load(f)\n",
    "        else:\n",
    "            raise\n",
    "        return booster, params\n",
    "    except Exception as e:\n",
    "        raise"
   ],
   "metadata": {
    "id": "Yk5Go-sjC1Df"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def save_booster(booster, params, booster_type='clf'):\n",
    "    try:\n",
    "        model_path = \"/tmp/\"\n",
    "        if booster_type == 'reg':\n",
    "            booster_name = \"stock_reg_booster.txt\"\n",
    "            params_name = \"stock_reg_params.json\"\n",
    "        else:\n",
    "            booster_name = \"stock_clf_booster.txt\"\n",
    "            params_name = \"stock_clf_params.json\"\n",
    "\n",
    "        s3_booster_key = f'models/stock/{booster_name}'\n",
    "        s3_params_key = f'models/stock/{params_name}'\n",
    "\n",
    "        booster.save_model(model_path+booster_name)\n",
    "        with open(model_path + params_name, 'w') as f:\n",
    "            json.dump(params, f)\n",
    "\n",
    "        # 업로드 수행\n",
    "        s3_client.upload_file(model_path+booster_name, bucket_name, s3_booster_key)\n",
    "        print(f\"업로드 완료: s3://{bucket_name}/{s3_booster_key}\")\n",
    "        s3_client.upload_file(model_path+params_name, bucket_name, s3_params_key)\n",
    "        print(f\"업로드 완료: s3://{bucket_name}/{s3_params_key}\")\n",
    "    except Exception as e:\n",
    "        raise"
   ],
   "metadata": {
    "id": "2reyRifeC8Xo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_and_save_models(df: pd.DataFrame):\n",
    "    print(\"\\n--- ML 모델 학습 및 예측 시작 ---\")\n",
    "    try:\n",
    "        if df.empty:\n",
    "            print(\"DataFrame is empty. Skipping training.\")\n",
    "            return\n",
    "\n",
    "        feature_cols = df.columns.difference(['trade_time_min', 'future_return', 'future_avg_price', 'target_direction'])\n",
    "\n",
    "        # --- train & save ---\n",
    "        split_idx = int(len(df) * 0.9)\n",
    "\n",
    "        clf_X, clf_y = df[feature_cols], df['target_direction']\n",
    "        clf_X_train, clf_X_test, clf_y_train, clf_y_test = clf_X[:split_idx], clf_X[split_idx:], clf_y[:split_idx], clf_y[split_idx:]\n",
    "        clf_train_data = lgb.Dataset(clf_X_train, label=clf_y_train)\n",
    "        clf_val_data = lgb.Dataset(clf_X_test, label=clf_y_test)\n",
    "\n",
    "        if len(np.unique(clf_y_train)) < 2:\n",
    "            print(\"Dataset is TOO small\")\n",
    "            return\n",
    "\n",
    "        clf_booster, clf_params = load_booster()\n",
    "        print(\"clf params: \", clf_params)\n",
    "        if 'metric' not in clf_params.keys():\n",
    "            clf_params['metric'] = 'multi_logloss'\n",
    "        clf_booster = lgb.train(clf_params, train_set=clf_train_data, valid_sets=[clf_val_data], init_model=clf_booster, num_boost_round=100, callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "        reg_X, reg_y = df[feature_cols], df['future_avg_price']\n",
    "        reg_X_train, reg_X_test, reg_y_train, reg_y_test = reg_X[:split_idx], reg_X[split_idx:], reg_y[:split_idx], reg_y[split_idx:]\n",
    "        reg_train_data = lgb.Dataset(reg_X_train, label=reg_y_train)\n",
    "        reg_val_data = lgb.Dataset(reg_X_test, label=reg_y_test)\n",
    "\n",
    "        reg_booster, reg_params = load_booster('reg')\n",
    "        print(\"reg params: \", reg_params)\n",
    "        if 'metric' not in reg_params.keys():\n",
    "            reg_params['metric'] = 'mae'\n",
    "        reg_booster = lgb.train(reg_params, train_set=reg_train_data, valid_sets=[reg_val_data], init_model=reg_booster, num_boost_round=100, callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "        reg_predictions = reg_booster.predict(reg_X_test)\n",
    "        clf_predictions = clf_booster.predict(clf_X_test)\n",
    "        clf_predictions = np.argmax(clf_predictions, axis=1)\n",
    "        mae = mean_absolute_error(reg_y_test, reg_predictions)\n",
    "        accuracy = accuracy_score(clf_y_test, clf_predictions)\n",
    "        display(confusion_matrix(clf_y_test, clf_predictions))\n",
    "        print(f\"정확도: {accuracy:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(\"학습 및 예측 완료\")\n",
    "\n",
    "        save_booster(clf_booster, clf_params)\n",
    "        save_booster(reg_booster, reg_params, 'reg')\n",
    "        return\n",
    "    except:\n",
    "        raise"
   ],
   "metadata": {
    "id": "el04kiNBDGkm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    raw = load_data(target_date)\n",
    "    data = generate_features(raw)\n",
    "    train_and_save_models(data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_bw08uHGDrNc",
    "outputId": "c8420708-b5dc-4634-f84d-d3105f0131bf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2025-07-22 → 1개 파일 불러옴\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-72-2847167443.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby('stock_code')['close_price'].transform(lambda x: x.rolling(window=1, min_periods=1).mean().shift(-1))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "전: (33330, 14)\n",
      "후: (30570, 14)\n",
      "\n",
      "--- ML 모델 학습 및 예측 시작 ---\n",
      "clf params:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': 'multiclass', 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'num_class': 3}\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5020\n",
      "[LightGBM] [Info] Number of data points in the train set: 27513, number of used features: 10\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 2 to 1), it may cause unexpected errors.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.876018\n",
      "reg params:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': 'regression_l1', 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5020\n",
      "[LightGBM] [Info] Number of data points in the train set: 27513, number of used features: 10\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 2 to 1), it may cause unexpected errors.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l1: 2589.58\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "array([[   0,    0,    0],\n",
       "       [  61, 2982,   14],\n",
       "       [   0,    0,    0]])"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "정확도: 0.9755\n",
      "MAE: 2589.5819\n",
      "학습 및 예측 완료\n",
      "업로드 완료: s3://de6-team7-bucket/models/stock/stock_clf_booster.txt\n",
      "업로드 완료: s3://de6-team7-bucket/models/stock/stock_clf_params.json\n",
      "업로드 완료: s3://de6-team7-bucket/models/stock/stock_reg_booster.txt\n",
      "업로드 완료: s3://de6-team7-bucket/models/stock/stock_reg_params.json\n"
     ]
    }
   ]
  }
 ]
}
