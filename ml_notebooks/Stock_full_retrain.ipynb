{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# parameters\n",
    "AWS_ACCESS_KEY_ID = None\n",
    "AWS_SECRET_ACCESS_KEY = None\n",
    "exec_date_str = None"
   ],
   "metadata": {
    "id": "RwuUGll5TiFv",
    "tags": [
     "parameters"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, confusion_matrix\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import json"
   ],
   "metadata": {
    "id": "aILkpCRcQlFy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 포맷 확인 후 가능한 경우 포맷 맞춰 변환, 불가능하면 None 반환\n",
    "def try_convert(s, fmt=\"%Y-%m-%d %H:%M:%S\"):\n",
    "    try:\n",
    "        dt = pd.to_datetime(s, errors='raise')  # 실패하면 예외 발생\n",
    "        return dt.strftime(fmt)\n",
    "    except:\n",
    "        return None"
   ],
   "metadata": {
    "id": "SGLoaDxdsK4H"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_recent_2weeks_data(exec_date_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    S3에서 exec_date_str 기준 최근 2주간의 데이터를 불러온다.\n",
    "    누락된 날짜가 있어도 가능한 데이터만 취합한다.\n",
    "    \"\"\"\n",
    "    # 문자열 날짜 -> datetime\n",
    "    exec_date = datetime.strptime(exec_date_str, '%Y-%m-%d')\n",
    "    start_date = exec_date - timedelta(days=13)  # 포함해서 14일치\n",
    "\n",
    "    print(f\"기준일: {exec_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"검색 기간: {start_date.strftime('%Y-%m-%d')} ~ {exec_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    df_all = []\n",
    "\n",
    "    for i in range(14):\n",
    "        target_date = (start_date + timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "        prefix = f\"derived_stock/stock_dt={target_date}/\" # 경로 수정\n",
    "\n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "            if 'Contents' not in response:\n",
    "                print(f\"누락된 날짜: {target_date} - 데이터 없음\")\n",
    "                continue\n",
    "\n",
    "            file_keys = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.parquet')]\n",
    "            if not file_keys:\n",
    "                print(f\"Parquet 파일 없음: {target_date}\")\n",
    "                continue\n",
    "\n",
    "            for key in file_keys:\n",
    "                s3_object = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "                buffer = io.BytesIO(s3_object['Body'].read())\n",
    "                df_temp = pd.read_parquet(buffer)\n",
    "\n",
    "                # stock_name을 제외하고 필요한 컬럼만 선택합니다.\n",
    "                df_temp = df_temp[['trade_time_min', 'stock_code', 'open_price', 'high_price', 'low_price', 'close_price', 'cum_volume', 'cum_amount', 'vwap_price', 'change_rate', 'spread']]\n",
    "\n",
    "                df_temp['trade_time_min'] = target_date + \" \" + df_temp['trade_time_min'].astype(str)\n",
    "                df_temp['trade_time_min'] = df_temp.apply(lambda row: try_convert(row['trade_time_min']), axis=1)\n",
    "                df_all.append(df_temp)\n",
    "\n",
    "            print(f\"{target_date} → {len(file_keys)}개 파일 불러옴\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{target_date} 처리 중 오류: {e}\")\n",
    "\n",
    "    if not df_all:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.concat(df_all, ignore_index=True)"
   ],
   "metadata": {
    "id": "ob6uUZUIQnL7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 전체 ML 학습 및 예측\n",
    "def train_and_save(df, price_change_threshold=0.002):\n",
    "    try:\n",
    "        print(\"\\n--- ML 모델 학습 및 예측 시작 ---\")\n",
    "        df.sort_values(by=['trade_time_min', 'stock_code'], inplace=True)\n",
    "        df['stock_code'] = df['stock_code'].astype('category')\n",
    "        df['future_avg_price'] = (\n",
    "            df.groupby('stock_code')['close_price'].transform(lambda x: x.rolling(window=60, min_periods=60).mean().shift(-59))\n",
    "        )\n",
    "        df['future_return'] = (df['future_avg_price'] - df['close_price']) / df['close_price']\n",
    "        df['target_direction'] = np.select(\n",
    "            [df['future_return'] > price_change_threshold,\n",
    "            df['future_return'] < -price_change_threshold],\n",
    "            [2, 0], default=1\n",
    "        )\n",
    "        df.dropna(subset=['future_avg_price', 'future_return'], inplace=True)\n",
    "        if df.empty:\n",
    "            print(\"Empty dataframe\")\n",
    "            return\n",
    "\n",
    "        # stock_name이 실수로 포함되었을 경우를 대비해 한 번 더 제외합니다.\n",
    "        feature_cols = [col for col in df.columns if col not in ['trade_time_min', 'stock_name', 'future_return', 'future_avg_price', 'target_direction']]\n",
    "\n",
    "        # --- train & save ---\n",
    "        clf_X, clf_y = df[feature_cols], df['target_direction']\n",
    "\n",
    "        split_idx = int(len(df) * 0.9)\n",
    "        clf_X_train, clf_X_test, clf_y_train, clf_y_test = clf_X[:split_idx], clf_X[split_idx:], clf_y[:split_idx], clf_y[split_idx:]\n",
    "\n",
    "        if len(np.unique(clf_y_train)) < 2:\n",
    "            print(\"Dataset is TOO small\")\n",
    "            return\n",
    "\n",
    "        clf_model = lgb.LGBMClassifier(objective='multiclass', num_class=3, random_state=42)\n",
    "        clf_model.fit(\n",
    "            clf_X_train, clf_y_train,\n",
    "            eval_set=[(clf_X_test, clf_y_test)],\n",
    "            categorical_feature=['stock_code'],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        )\n",
    "\n",
    "        reg_X, reg_y = df[feature_cols], df['future_avg_price']\n",
    "        reg_X_train, reg_X_test, reg_y_train, reg_y_test = reg_X[:split_idx], reg_X[split_idx:], reg_y[:split_idx], reg_y[split_idx:]\n",
    "\n",
    "        reg_model = lgb.LGBMRegressor(objective='regression_l1', random_state=42)\n",
    "        reg_model.fit(\n",
    "            reg_X_train, reg_y_train,\n",
    "            eval_set=[(reg_X_test, reg_y_test)],\n",
    "            categorical_feature=['stock_code'],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        )\n",
    "\n",
    "        reg_predictions = reg_model.predict(reg_X_test)\n",
    "\n",
    "        clf_predictions = clf_model.predict(clf_X_test)\n",
    "        mae = mean_absolute_error(reg_y_test, reg_predictions)\n",
    "        accuracy = accuracy_score(clf_y_test, clf_predictions)\n",
    "        display(confusion_matrix(clf_y_test, clf_predictions))\n",
    "        print(f\"정확도: {accuracy:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(\"학습 및 예측 완료\")\n",
    "\n",
    "        # asset_type을 'stock'으로 명시하여 저장합니다.\n",
    "        save_model(clf_model)\n",
    "        save_model(reg_model,model_type='reg')\n",
    "        return\n",
    "    except:\n",
    "        raise"
   ],
   "metadata": {
    "id": "6cAmibPbwm8m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def save_model(model, model_type='clf'):\n",
    "    try:\n",
    "        model_path = \"/tmp/\"\n",
    "        if model_type == 'reg':\n",
    "            booster_name = \"stock_reg_booster.txt\"\n",
    "            params_name = \"stock_reg_params.json\"\n",
    "        else:\n",
    "            booster_name = \"stock_clf_booster.txt\"\n",
    "            params_name = \"stock_clf_params.json\"\n",
    "        booster = model.booster_\n",
    "        params = model.get_params()\n",
    "        booster.save_model(model_path+booster_name)\n",
    "        with open(model_path + params_name, 'w') as f:\n",
    "            json.dump(params, f)\n",
    "\n",
    "        s3_booster_key = f'models/stock/{booster_name}'\n",
    "        s3_params_key = f'models/stock/{params_name}'\n",
    "\n",
    "        # 업로드 수행\n",
    "        s3_client.upload_file(model_path+booster_name, bucket_name, s3_booster_key)\n",
    "        s3_client.upload_file(model_path+params_name, bucket_name, s3_params_key)\n",
    "        print(f\"업로드 완료\")\n",
    "    except Exception as e:\n",
    "        raise"
   ],
   "metadata": {
    "id": "fQ2eLVTB2lfA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "aws_access_key_id = AWS_ACCESS_KEY_ID\n",
    "aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket_name = \"de6-team7-bucket\"\n",
    "prefix = \"derived_stock/\"\n",
    "\n",
    "try:\n",
    "    der_df = load_recent_2weeks_data(exec_date_str)\n",
    "    train_and_save(der_df)\n",
    "    print(\"---------------------------------------------\")\n",
    "except Exception as e:\n",
    "    raise"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "id": "tKyvrZLi2HUo",
    "outputId": "b9db3bff-f818-40b6-f978-9d7543ad04f1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "기준일: 2025-07-22\n",
      "검색 기간: 2025-07-09 ~ 2025-07-22\n",
      "누락된 날짜: 2025-07-09 - 데이터 없음\n",
      "2025-07-10 → 1개 파일 불러옴\n",
      "2025-07-11 → 1개 파일 불러옴\n",
      "2025-07-12 → 1개 파일 불러옴\n",
      "2025-07-13 → 1개 파일 불러옴\n",
      "2025-07-14 → 1개 파일 불러옴\n",
      "2025-07-15 → 1개 파일 불러옴\n",
      "2025-07-16 → 1개 파일 불러옴\n",
      "2025-07-17 → 1개 파일 불러옴\n",
      "2025-07-18 → 1개 파일 불러옴\n",
      "2025-07-19 → 1개 파일 불러옴\n",
      "2025-07-20 → 1개 파일 불러옴\n",
      "2025-07-21 → 1개 파일 불러옴\n",
      "2025-07-22 → 1개 파일 불러옴\n",
      "\n",
      "--- ML 모델 학습 및 예측 시작 ---\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-22-3728859195.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby('stock_code')['close_price'].transform(lambda x: x.rolling(window=60, min_periods=60).mean().shift(-59))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5025\n",
      "[LightGBM] [Info] Number of data points in the train set: 94262, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.716220\n",
      "[LightGBM] [Info] Start training from score -1.887358\n",
      "[LightGBM] [Info] Start training from score -1.021838\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5025\n",
      "[LightGBM] [Info] Number of data points in the train set: 94262, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 5594.750000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "array([[4524,  164,  605],\n",
       "       [ 462,  954,  330],\n",
       "       [ 739,  143, 2553]])"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "정확도: 0.7668\n",
      "MAE: 2643.3477\n",
      "학습 및 예측 완료\n",
      "업로드 완료\n",
      "업로드 완료\n",
      "---------------------------------------------\n"
     ]
    }
   ]
  }
 ]
}
